% This file was created with JabRef 2.8.1.
% Encoding: UTF8

@PHDTHESIS{burgoynephd,
  author = {Burgoyne, John Ashley},
  title = {Stochastic Processes and Database-Driven Musicology},
  school = {McGill University},
  year = {2012},
  address = {Montr\'eal, Qu\'ebec, Canada},
  owner = {haas0118},
  timestamp = {2013.02.11},
  url = {http://digitool.Library.McGill.CA:80/R/-?func=dbin-jump-full&object_id=107704&silo_library=GEN01}
}

@INPROCEEDINGS{burgoyne2011,
  author = {Burgoyne, J. A. and Wild, J. and Fujinaga, I.},
  title = {An expert ground truth set for audio chord recognition and music
	analysis},
  booktitle = {Proceedings of the 12th International Society for Music Information
	Retrieval Conference (ISMIR)},
  year = {2011},
  pages = {633-638},
  owner = {bash},
  timestamp = {2013.02.06}
}

@ARTICLE{haas2012,
  author = {De Haas, W Bas and Magalhaes, Jos{\'e} Pedro and ten Heggeler, Dion
	and Bekenkamp, Gijs and Ruizendaal, Tijmen},
  title = {Chordify: Chord transcription for the masses},
  journal = {Demonstration presented at the International Society for Music Information
	Retrieval Conference},
  year = {2012},
  pages = {8--12},
  owner = {bash},
  timestamp = {2014.05.03}
}

@TECHREPORT{haas-burgoyne2012,
  author = {de Haas, W.B. and Burgoyne, John~Ashley},
  title = {Parsing the Billboard Chord Transcriptions},
  institution = {Department of Information and Computing Sciences, Utrecht University},
  year = {2012},
  number = {UU-CS-2012-018},
  owner = {bash},
  pubcat = {techreport},
  timestamp = {2014.05.03},
  urlpdf = {{http://www.cs.uu.nl/research/techreps/repo/CS-2012/2012-018.pdf}}
}

@INPROCEEDINGS{haas2011,
  author = {de Haas, W Bas and Magalhaes, Jos{\'e} Pedro and Veltkamp, Remco
	C and Wiering, Frans},
  title = {HarmTrace: improving harmonic similarity estimation using functional
	harmony analysis},
  booktitle = {International Society for Music Information Retrieval Conference
	(ISMIR)},
  year = {2011},
  pages = {67--72},
  owner = {bash},
  timestamp = {2014.05.03}
}

@PHDTHESIS{harte2010,
  author = {Harte, Christopher},
  title = {Towards automatic extraction of harmony information from music signals},
  school = {University of London},
  year = {2010},
  owner = {bash},
  timestamp = {2014.05.03}
}

@INPROCEEDINGS{khadkevich2013,
  author = {Maksim Khadkevich, Maurizio Omologo},
  title = {Large-scale cover song identification using chord profiles},
  booktitle = {Proceedings of the 14th International Conference on Music Information
	Retrieval (ISMIR)},
  year = {2013},
  pages = {233--238},
  owner = {bash},
  timestamp = {2014.05.03}
}

@PHDTHESIS{mauch2010,
  author = {Matthias Mauch},
  title = {Automatic Chord Transcription from Audio Using Computational Models
	of Musical Context},
  school = {Queen Mary University of London},
  year = {2010},
  abstract = {This thesis is concerned with the automatic transcription of chords
	from audio, with an emphasis on modern popular music. Musical context
	such as the key and the structural segmentation aid the interpretation
	of chords in human beings. In this thesis we propose computational
	models that integrate such musical context into the automatic chord
	estimation process. We present a novel dynamic Bayesian network (DBN)
	which integrates models of metric position, key, chord, bass note
	and two beat-synchronous audio features (bass and treble chroma)
	into a single high-level musical context model. We simultaneously
	infer the most probable sequence of metric positions, keys, chords
	and bass notes via Viterbi inference. Several experiments with real
	world data show that adding context parameters results in a significant
	increase in chord recognition accuracy and faithfulness of chord
	segmentation. The proposed, most complex method transcribes chords
	with a state-of-the-art accuracy of 73% on the song collection used
	for the 2009 MIREX Chord Detection tasks. This method is used as
	a baseline method for two further enhancements. Firstly, we aim to
	improve chord confusion behaviour by modifying the audio front end
	processing. We compare the effect of learning chord profiles as Gaussian
	mixtures to the effect of using chromagrams generated from an approximate
	pitch transcription method. We show that using chromagrams from approximate
	transcription results in the most substantial increase in accuracy.
	The best method achieves 79% accuracy and significantly outperforms
	the state of the art.Secondly, we propose a method by which chromagram
	information is shared between repeated structural segments (such
	as verses) in a song. This can be done fully automatically using
	a novel structural segmentation algorithm tailored to this task.
	We show that the technique leads to a significant increase in accuracy
	and readability. The segmentation algorithm itself also obtains state-of-the-art
	results. A method that combines both of the above enhancements reaches
	an accuracy of 81%, a statistically significant improvement over
	the best result (74%) in the 2009 MIREX Chord Detection tasks.},
  owner = {Bas},
  timestamp = {2011.07.03}
}

@INPROCEEDINGS{mauch2007,
  author = {Mauch, M. and Dixon, S. and Harte, C. and Casey, M. and Fields, B.},
  title = {{Discovering chord idioms through beatles and real book songs}},
  booktitle = {Proceedings of the 8th International Conference on Music Information
	Retrieval (ISMIR)},
  year = {2007},
  pages = {255--258},
  owner = {bash},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Pauwels-Peeters-2013,
  author = {Pauwels, Johan and Peeters, Geoffroy},
  title = {Evaluating Automatically Estimated Chord Sequences},
  booktitle = {Proceedings of the 38th \acro{IEEE} International Conference on Acoustics,
	Speech, and Signal Processing},
  year = {2013},
  address = {Vancouver, British Columbia},
  bdsk-file-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQS4uLy4uLy4uLy4uLy4uL1BhcGVycy9PbSB0ZSBsZXplbi8yMDEzL1BhdXdlbHMgJiBQZWV0ZXJzIDIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAdQAAAAAAdQAAgAADENlcmluIEFtcm90aAAAAAAAAAAAAAAAAAAAAMvhxgBIKwAAAa668xpQYXV3ZWxzICYgUGVldGVycyAyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwUJ9zeEMqgAAAAAAAAAAAAUABAAACSAAAAAAAAAAAAAAAAAAAAAEMjAxMwAQAAgAAMvhqeAAAAARAAgAAM3g8IoAAAABABQBrrrzABpWmAAGT4oABfXTAADAKQACAFNDZXJpbiBBbXJvdGg6VXNlcnM6AGNlbGVib3JuOgBQYXBlcnM6AE9tIHRlIGxlemVuOgAyMDEzOgBQYXV3ZWxzICYgUGVldGVycyAyMDEzLnBkZgAADgA2ABoAUABhAHUAdwBlAGwAcwAgACYAIABQAGUAZQB0AGUAcgBzACAAMgAwADEAMwAuAHAAZABmAA8AGgAMAEMAZQByAGkAbgAgAEEAbQByAG8AdABoABIAQVVzZXJzL2NlbGVib3JuL1BhcGVycy9PbSB0ZSBsZXplbi8yMDEzL1BhdXdlbHMgJiBQZWV0ZXJzIDIwMTMucGRmAAATAAEvAAAVAAIAD///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOANIA1wDfArcCuQK+AskC0gLgAuQC6wL0AvkDBgMJAxsDHgMjAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyU=},
  date-added = {2014-05-03 08:30:23 +0000},
  date-modified = {2014-05-03 08:30:23 +0000},
  keywords = {chord recognition}
}

